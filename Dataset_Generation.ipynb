{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing necessary packages, can ask the users to restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt-get install -y libjpeg-dev zlib1g-dev  # Do this, if pillow fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HDODJsdzNY3t",
    "outputId": "20c23249-521b-48bb-a53f-c635f4f46cee"
   },
   "outputs": [],
   "source": [
    "%pip install scikit-image PyMuPDF python-docx opencv-python scipy torch torchvision==0.2.1 pillow==8.3.1 tensorflow==2.15 gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stHue-JK4Et3"
   },
   "source": [
    "You will be prompted to Restart the session. Continue running the cells after restarting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elI3lOO-NZtO"
   },
   "source": [
    "# Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FNy5s-zyOOKw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 18:57:53.655177: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-22 18:57:53.682192: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-22 18:57:53.682221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-22 18:57:53.683109: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-22 18:57:53.687842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-22 18:57:54.279596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Data Pre-processing\n",
    "import fitz\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "from docx import Document\n",
    "import string\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from IPython.display import clear_output as cls\n",
    "\n",
    "# Data\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow.data as tfd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zjB7D6BOO17"
   },
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PS6eYteOToV",
    "outputId": "9c6ee95d-fa99-4734-e3c0-7ca2bb1803c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: http://drive.google.com/uc?id=10NX_UbV2HMbPEO2fvKYAIXOOOec0g38g\n",
      "To: /home/shashank/Desktop/GSOC'25/HumanAI_Task_submission_1/Padilla - Nobleza virtuosa_testExtract.pdf\n",
      "100%|██████████████████████████████████████| 2.58M/2.58M [00:00<00:00, 6.39MB/s]\n",
      "Downloading...\n",
      "From: http://drive.google.com/uc?id=1YTaqNoZCYP74AuQxlyJsiQLhcoc8DNSv\n",
      "To: /home/shashank/Desktop/GSOC'25/HumanAI_Task_submission_1/Padilla - 1 Nobleza virtuosa_testTranscription.docx\n",
      "100%|██████████████████████████████████████| 29.1k/29.1k [00:00<00:00, 1.73MB/s]\n",
      "Downloading...\n",
      "From: http://drive.google.com/uc?id=1x6FS3z4WhsHS7s38a2oSH8JnLQ_u_f21\n",
      "To: /home/shashank/Desktop/GSOC'25/HumanAI_Task_submission_1/Padilla - 2 Noble perfecto_Extract.pdf\n",
      "100%|██████████████████████████████████████| 3.95M/3.95M [00:00<00:00, 7.28MB/s]\n",
      "Downloading...\n",
      "From: http://drive.google.com/uc?id=1YqQ04ZQR4xdjKlQS9xL9zkkWYx_Ppxwa\n",
      "To: /home/shashank/Desktop/GSOC'25/HumanAI_Task_submission_1/Padilla - 2 Noble perfecto_Transcription.docx\n",
      "100%|███████████████████████████████████████| 32.2k/32.2k [00:00<00:00, 488kB/s]\n",
      "Downloading...\n",
      "From (original): http://drive.google.com/uc?id=1r7TjJ9RjNZHxAzKhd4uOaRWanrQXIqw8\n",
      "From (redirected): https://drive.google.com/uc?id=1r7TjJ9RjNZHxAzKhd4uOaRWanrQXIqw8&confirm=t&uuid=a340c9ca-dd57-4678-a54a-28739a814c47\n",
      "To: /home/shashank/Desktop/GSOC'25/HumanAI_Task_submission_1/utils.py\n",
      "100%|███████████████████████████████████████| 17.0k/17.0k [00:00<00:00, 431kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading the Dataset on collab/local notebook\n",
    "\n",
    "# Virtuosa ( Dataset 1)\n",
    "!gdown 'http://drive.google.com/uc?id=10NX_UbV2HMbPEO2fvKYAIXOOOec0g38g'  # Downloading link for Ancient Text\n",
    "!gdown 'http://drive.google.com/uc?id=1YTaqNoZCYP74AuQxlyJsiQLhcoc8DNSv'  # Downloading link for Ground Truth Text\n",
    "\n",
    "# Perfecto ( Dataset 2)\n",
    "!gdown 'http://drive.google.com/uc?id=1x6FS3z4WhsHS7s38a2oSH8JnLQ_u_f21'  # Downloading link for Ancient Text\n",
    "!gdown 'http://drive.google.com/uc?id=1YqQ04ZQR4xdjKlQS9xL9zkkWYx_Ppxwa'  # Downloading link for Ground Truth Text\n",
    "\n",
    "!gdown 'http://drive.google.com/uc?id=1r7TjJ9RjNZHxAzKhd4uOaRWanrQXIqw8' # Downloading utils.py from cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1_XnH9QOrbE",
    "outputId": "ea35c38d-2397-4c90-8d11-64e3ccb842a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset_Generation.ipynb\n",
      " Model.ipynb\n",
      "'Padilla - 1 Nobleza virtuosa_testTranscription.docx'\n",
      "'Padilla - 2 Noble perfecto_Extract.pdf'\n",
      "'Padilla - 2 Noble perfecto_Transcription.docx'\n",
      "'Padilla - Nobleza virtuosa_testExtract.pdf'\n",
      " README.md\n",
      " utils.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjsuG_mJOwBk"
   },
   "source": [
    "# Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3g_AanojUG3"
   },
   "source": [
    "### Converting PDF to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BiOV4cLmOxFT"
   },
   "outputs": [],
   "source": [
    "from utils import pdf_to_images\n",
    "\n",
    "pdf_path1 = \"./Padilla - Nobleza virtuosa_testExtract.pdf\"  # Path to the PDF file\n",
    "unproc_images_folder_1 = \"./preprocessing/imgsUnProcessed1\"  # Output folder to save the images\n",
    "if not os.path.exists(unproc_images_folder_1):\n",
    "    os.makedirs(unproc_images_folder_1)\n",
    "pdf_to_images(pdf_path1, unproc_images_folder_1)\n",
    "\n",
    "\n",
    "pdf_path2 = \"./Padilla - 2 Noble perfecto_Extract.pdf\"  # Path to the PDF file\n",
    "unproc_images_folder_2 = \"./preprocessing/imgsUnProcessed2\"  # Output folder to save the images\n",
    "if not os.path.exists(unproc_images_folder_2):\n",
    "    os.makedirs(unproc_images_folder_2)\n",
    "pdf_to_images(pdf_path2, unproc_images_folder_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95x4qua187Mb"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ML4SCI/DeepLearnHackathon/main/NLPRenaissanceChallenge/images/imageOriginal.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0GKH7lTjtUP"
   },
   "source": [
    "### Splitting two sided scanned images into individual pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxE9-mExPPQp",
    "outputId": "18641458-dd00-4dfc-eae8-b068957c52eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing complete!\n"
     ]
    }
   ],
   "source": [
    "#Segregating 2-sided pages into individual pages\n",
    "from utils import process_images\n",
    "\n",
    "unproc_images_folder_1 = \"./preprocessing/imgsUnProcessed1\"\n",
    "proc_images_folder_1 = \"./preprocessing/imgsForAllPages1\"\n",
    "if not os.path.exists(proc_images_folder_1):\n",
    "    os.makedirs(proc_images_folder_1)\n",
    "process_images(unproc_images_folder_1, proc_images_folder_1)\n",
    "\n",
    "\n",
    "unproc_images_folder_2 = \"./preprocessing/imgsUnProcessed2\"\n",
    "proc_images_folder_2 = \"./preprocessing/imgsForAllPages2\"\n",
    "if not os.path.exists(proc_images_folder_2):\n",
    "    os.makedirs(proc_images_folder_2)\n",
    "process_images(unproc_images_folder_2, proc_images_folder_2)\n",
    "\n",
    "print(\"Image processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOVaNBR1PPOf",
    "outputId": "945c191f-a778-4ce5-8303-6bbd07ba8b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CRAFT_Model'...\n",
      "remote: Enumerating objects: 28, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 28 (delta 0), reused 3 (delta 0), pack-reused 23 (from 1)\u001b[K\n",
      "Receiving objects: 100% (28/28), 73.69 MiB | 3.54 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Shashankss1205/CRAFT_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DegjoeDpj6XO"
   },
   "source": [
    "# Text Detection\n",
    "### Extracting words from a scanned text page image can be achieved using any model of your choice. We are using the [CRAFT Model](https://github.com/clovaai/CRAFT-pytorch) for the same. (This will take 1-2 mins to process the entire model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WihUk3I9PO-_",
    "outputId": "f2e7c4ed-af34-40ca-f2fb-cf366221530b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (CRAFT_Model/CRAFT/BoundBoxFunc/weights/craft_mlt_25k.pth)\n",
      "elapsed time : 18.305070877075195simgsForAllPages1/image_15.png\n"
     ]
    }
   ],
   "source": [
    "#It generally takes about ~3-4 mins\n",
    "!python3 CRAFT_Model/CRAFT/BoundBoxFunc/test.py --cuda 1 --result_folder='./preprocessing/BoundBoxApplied1/' --test_folder=\"./preprocessing/imgsForAllPages1\" --trained_model='CRAFT_Model/CRAFT/BoundBoxFunc/weights/craft_mlt_25k.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (CRAFT_Model/CRAFT/BoundBoxFunc/weights/craft_mlt_25k.pth)\n",
      "elapsed time : 18.559587001800537simgsForAllPages2/image_15.png\n"
     ]
    }
   ],
   "source": [
    "#It generally takes about ~3-4 mins\n",
    "!python3 CRAFT_Model/CRAFT/BoundBoxFunc/test.py --cuda 1 --result_folder='./preprocessing/BoundBoxApplied2/' --test_folder=\"./preprocessing/imgsForAllPages2\" --trained_model='CRAFT_Model/CRAFT/BoundBoxFunc/weights/craft_mlt_25k.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAN5mE9UlMtT"
   },
   "source": [
    "### The output of this model provides coordinates of the polygon enclosing the word. Using these coordinates one can draw a bounding box and crop word images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IOkMKjs1QKTA"
   },
   "outputs": [],
   "source": [
    "#Sorting the BB based on the Spanish writing style\n",
    "from utils import sort_bounding_boxes\n",
    "\n",
    "bound_box_applied1 = './preprocessing/BoundBoxApplied1/'\n",
    "bound_box_sorted1 = \"./preprocessing/BoundBoxSorted1\"\n",
    "if not os.path.exists(bound_box_sorted1):\n",
    "    os.makedirs(bound_box_sorted1)\n",
    "sort_bounding_boxes(bound_box_applied1, bound_box_sorted1)\n",
    "\n",
    "bound_box_applied2 = './preprocessing/BoundBoxApplied2/'\n",
    "bound_box_sorted2 = \"./preprocessing/BoundBoxSorted2\"\n",
    "if not os.path.exists(bound_box_sorted2):\n",
    "    os.makedirs(bound_box_sorted2)\n",
    "sort_bounding_boxes(bound_box_applied2, bound_box_sorted2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lEq-eGQAnHz"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ML4SCI/DeepLearnHackathon/main/NLPRenaissanceChallenge/images/imageCRAFT.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55_AJ77JmRK1"
   },
   "source": [
    "### Extracting all the words from .docx file containing Transcription (True lables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ovyxoTMNQKQf"
   },
   "outputs": [],
   "source": [
    "#ground truth to text code\n",
    "from utils import save_pages_to_text\n",
    "\n",
    "docx_file1 = \"./Padilla - 1 Nobleza virtuosa_testTranscription.docx\"\n",
    "grnd_truth1 = \"./preprocessing/all_text1.txt\"     # File where the complete processed text will be saved\n",
    "save_pages_to_text(docx_file1, grnd_truth1)\n",
    "\n",
    "docx_file2 = \"./Padilla - 2 Noble perfecto_Transcription.docx\"\n",
    "grnd_truth2 = \"./preprocessing/all_text2.txt\"     # File where the complete processed text will be saved\n",
    "save_pages_to_text(docx_file2, grnd_truth2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVtXy1SrmqSF"
   },
   "source": [
    "### Since we have processed our text book into individual pages, we need to split the entire transcription based on text pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTtUbDhzQPW-",
    "outputId": "adb32158-5425-4700-bad4-fb0157567209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 files in the folder\n",
      "31 files in the folder\n",
      "Text splitting complete!\n"
     ]
    }
   ],
   "source": [
    "#splitting text files, based on the text\n",
    "from utils import process_textfiles\n",
    "\n",
    "grnd_truth1 = \"./preprocessing/all_text1.txt\"\n",
    "bound_box_sorted1 = './preprocessing/BoundBoxSorted1'\n",
    "proc_grnd_truth1 = \"./preprocessing/textSplitted1\"\n",
    "TEST_SIZE=6\n",
    "if not os.path.exists(proc_grnd_truth1):\n",
    "    os.makedirs(proc_grnd_truth1)\n",
    "process_textfiles(grnd_truth1, bound_box_sorted1, proc_grnd_truth1, TEST_SIZE)\n",
    "\n",
    "\n",
    "grnd_truth2 = \"./preprocessing/all_text2.txt\" \n",
    "bound_box_sorted2 = './preprocessing/BoundBoxSorted2'\n",
    "proc_grnd_truth2 = \"./preprocessing/textSplitted2\"\n",
    "TEST_SIZE=0\n",
    "if not os.path.exists(proc_grnd_truth2):\n",
    "    os.makedirs(proc_grnd_truth2)\n",
    "process_textfiles(grnd_truth2, bound_box_sorted2, proc_grnd_truth2, TEST_SIZE)\n",
    "print(\"Text splitting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xz7pSRIEFoiC"
   },
   "source": [
    "### Extracts and saves bounding boxes from images using text data for filenames, skipping the last 6 images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dqDd50FKQPUm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pages 25\n",
      "Training pages 31\n"
     ]
    }
   ],
   "source": [
    "from utils import apply_extraction_to_folder_for_train, count_files_in_folder\n",
    "\n",
    "proc_images_folder_1 = './preprocessing/imgsForAllPages1'\n",
    "bound_box_sorted1 = './preprocessing/BoundBoxSorted1'\n",
    "proc_grnd_truth1 = './preprocessing/textSplitted1'\n",
    "training_data1 = './traning_data1'\n",
    "test_size=6\n",
    "train_size = count_files_in_folder(proc_images_folder_1, ['.png', '.jpeg', '.jpg'])- test_size\n",
    "print(\"Training pages \" +  str(train_size))\n",
    "if not os.path.exists(training_data1):\n",
    "    os.makedirs(training_data1)\n",
    "apply_extraction_to_folder_for_train(proc_images_folder_1, bound_box_sorted1, proc_grnd_truth1, training_data1, train_size)\n",
    "\n",
    "\n",
    "proc_images_folder_2 = './preprocessing/imgsForAllPages2'\n",
    "bound_box_sorted2 = './preprocessing/BoundBoxSorted2'\n",
    "proc_grnd_truth2 = './preprocessing/textSplitted2'\n",
    "training_data2 = './traning_data2'\n",
    "test_size = 0\n",
    "train_size = count_files_in_folder(proc_images_folder_1, ['.png', '.jpeg', '.jpg'])- test_size\n",
    "print(\"Training pages \" +  str(train_size))\n",
    "if not os.path.exists(training_data2):\n",
    "    os.makedirs(training_data2)\n",
    "apply_extraction_to_folder_for_train(proc_images_folder_2, bound_box_sorted2, proc_grnd_truth2, training_data2, train_size) # better to send no. of pages given in transcription"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
